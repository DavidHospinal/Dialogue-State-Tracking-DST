# ü§ñ Multi-Task BERT Model for Schema-Guided Dialogue State Tracking (DST)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.0-orange.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/Transformers-4.18.0-yellow.svg)](https://huggingface.co/transformers/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Paper](https://img.shields.io/badge/Paper-Interspeech%202022-red.svg)](https://www.isca-speech.org/archive/interspeech_2022/kapelonis22_interspeech.html)

> **Implementaci√≥n completa del paper "A Multi-Task BERT Model for Schema-Guided Dialogue State Tracking"** (Kapelonis et al., 2022) para optimizaci√≥n de di√°logos inteligentes en sistemas conversacionales.
![dstgenerated-image (2)](https://github.com/user-attachments/assets/7600ddb3-c0c4-47d1-8946-6ad269bcbea7)

---

## üìä Resultados Destacados

Nuestro modelo entrenado alcanz√≥ un rendimiento excepcional en el dataset Schema-Guided Dialogue (SGD):

| M√©trica | Iteraci√≥n 4 (Epoch 5) | Benchmark |
|---------|----------------------|-----------|
| **Joint Goal Accuracy** | **80.35%** | üèÜ State-of-the-art |
| **Requested Slots F1** | **99.33%** | ü•á Excelente |
| **Active Intent Accuracy** | 95.52% | ‚úÖ Superior |
| **Average Goal Accuracy** | 94.88% | ‚úÖ Muy bueno |
| **Requested Slots Precision** | 99.66% | üéØ Casi perfecto |
| **Requested Slots Recall** | 99.44% | üéØ Casi perfecto |

### üìà Evoluci√≥n por Iteraciones

| Iteraci√≥n | Epochs | Batch Size | JGA | Req Slots F1 | Tiempo Entrenamiento |
|-----------|--------|------------|-----|--------------|---------------------|
| 1 | 3 | 16 | 65.88% | 97.92% | ~10 min |
| 2 | 3 | 24 | 79.80% | 99.23% | ~7 min |
| 3 | 4 | 24 | 80.57% | 99.38% | ~9 min |
| **4** | **5** | **24** | **80.35%** | **99.33%** | **~11 min** |

> **üìù Nota:** Iteraci√≥n 4 seleccionada como mejor modelo por balance entre precisi√≥n y eficiencia.

---

## üé• Video Tutorial Completo

[![Tutorial YouTube](https://img.shields.io/badge/YouTube-Tutorial%20Completo-red?style=for-the-badge&logo=youtube)](https://youtu.be/bgHbBYNNkEI)

**Contenido del video:**
- Introducci√≥n al Dialogue State Tracking
- Arquitectura del modelo Multi-Task BERT
- Proceso de entrenamiento y optimizaci√≥n
- An√°lisis de resultados y m√©tricas
- Aplicaciones pr√°cticas en e-Contact

---

## üèóÔ∏è Arquitectura del Modelo

```mermaid
graph TD
    A[User Input] --> B[BERT Tokenizer]
    B --> C[BERT Encoder]
    C --> D[Classification Heads]
    D --> E[Intent Prediction]
    D --> F[Requested Slots]
    D --> G[Slot Filling]
    D --> H[Slot Carryover]
    E --> I[Dialogue State]
    F --> I
    G --> I
    H --> I
```

### Componentes Principales

**Multi-Task Learning:**
- ‚úÖ **Intent Prediction**: Determina la intenci√≥n activa del usuario
- ‚úÖ **Requested Slot Prediction**: Identifica slots solicitados
- ‚úÖ **Slot Filling**: Asigna valores a slots bas√°ndose en la entrada
- ‚úÖ **Slot Carryover**: Conserva informaci√≥n relevante entre turnos

**Modelo Base:**
- üîπ BERT-base-uncased (12 capas, 768 dimensiones, 12 attention heads)
- üîπ Fine-tuned sobre Schema-Guided Dialogue Dataset
- üîπ Optimizado con AdamW (lr=2e-5, dropout=0.3)

---

## üöÄ Instalaci√≥n y Uso

### Prerrequisitos

- Python 3.8+
- CUDA 11.0+ (para entrenamiento con GPU)
- 16GB RAM m√≠nimo
- GPU con 8GB+ VRAM (recomendado: T4, V100)

### 1. Clonar el Repositorio

```bash
git clone https://github.com/DavidHospinal/Dialogue-State-Tracking-DST.git
cd Dialogue-State-Tracking-DST
```

### 2. Instalar Dependencias

```bash
pip install -r requirements.txt
```

**Dependencias principales:**
```
torch==2.1.0
transformers==4.18.0
tensorflow>=2.6.3
numpy>=1.16.1
tqdm, scikit-learn, matplotlib, nltk
```

### 3. Descargar el Dataset SGD

```bash
# El dataset Schema-Guided Dialogue est√° disponible en:
# https://github.com/google-research-datasets/dstc8-schema-guided-dialogue

# Estructura esperada:
# data/dstc8-schema-guided-dialogue/
#   ‚îú‚îÄ‚îÄ train/
#   ‚îú‚îÄ‚îÄ dev/
#   ‚îî‚îÄ‚îÄ test/
```

### 4. Entrenamiento por √âpocas

```bash
# Entrenamiento completo (5 epochs, batch size 24)
python -m src.train --num_epochs=5 --batch_size=24 --learning_rate=2e-5

# Opciones de configuraci√≥n en src/config.py:
# - MAX_SEQ_LEN: 512 (longitud m√°xima de secuencia)
# - WORD_DROPOUT: 0.1 (dropout para embeddings)
# - BATCH_SIZE: 24 (tama√±o de lote)
# - LEARNING_RATE: 2e-5 (tasa de aprendizaje)
```

### 5. Evaluaci√≥n con Modelo Pre-entrenado

```bash
# Usar el checkpoint best.pt incluido (Iteraci√≥n 4 - Epoch 5)
python -m src.dst --checkpoint_path=checkpoints/best.pt --eval_dataset=dev

# El modelo best.pt tiene JGA de 80.35% y Req Slots F1 de 99.33%
```

---

## üìÅ Estructura del Proyecto

```
Dialogue-State-Tracking-DST/
‚îú‚îÄ‚îÄ README.md                       # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                # Dependencias de Python
‚îú‚îÄ‚îÄ LICENSE                         # Licencia MIT
‚îÇ
‚îú‚îÄ‚îÄ src/                            # C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # Configuraci√≥n e hiperpar√°metros
‚îÇ   ‚îú‚îÄ‚îÄ models.py                   # Arquitectura Multi-Task BERT
‚îÇ   ‚îú‚îÄ‚îÄ train.py                    # Script de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ dst.py                      # L√≥gica de DST
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Procesamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classes.py              # Clases de di√°logos y estados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dialogue_processing.py # Procesamiento de di√°logos SGD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_extraction.py  # Extracci√≥n de caracter√≠sticas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input_sequence.py      # Preparaci√≥n de secuencias
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sgd_dataset.py         # Dataset SGD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pytorch_dataset.py     # PyTorch DataLoader
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ schema_guided_dst/          # Evaluaci√≥n y m√©tricas
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py              # C√°lculo de JGA, F1, etc.
‚îÇ       ‚îú‚îÄ‚îÄ evaluate.py             # Evaluaci√≥n completa
‚îÇ       ‚îî‚îÄ‚îÄ baseline/               # Baseline de Google DSTC8
‚îÇ
‚îú‚îÄ‚îÄ checkpoints/                    # Modelos entrenados
‚îÇ   ‚îî‚îÄ‚îÄ best.pt                     # Mejor modelo (JGA 80.35%) [1.3GB]
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Datos de entrenamiento
‚îÇ   ‚îî‚îÄ‚îÄ sample_sgd/                 # Muestras del dataset (opcional)
‚îÇ
‚îú‚îÄ‚îÄ docs/                           # Documentaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ DDSDI-Informe-Corporativo.pdf  # Informe t√©cnico completo
‚îÇ
‚îî‚îÄ‚îÄ results/                        # Resultados de experimentos
    ‚îú‚îÄ‚îÄ training_logs_epoch5.txt    # Logs de entrenamiento
    ‚îî‚îÄ‚îÄ metrics_iter4.json          # M√©tricas de iteraci√≥n 4
```

---

## üìñ M√©tricas de Evaluaci√≥n

### M√©tricas Principales

1. **Joint Goal Accuracy (JGA)**: Precisi√≥n conjunta para predicci√≥n de intenciones, slots categ√≥ricos y no categ√≥ricos
2. **Requested Slots F1**: F1-score para identificaci√≥n de slots solicitados
3. **Active Intent Accuracy**: Precisi√≥n de predicci√≥n de intenci√≥n activa
4. **Average Goal Accuracy**: Precisi√≥n promedio de predicci√≥n de objetivos

### Evaluaci√≥n por Servicios

El modelo fue evaluado en 3 conjuntos:
- **#ALL_SERVICES**: Todos los servicios (20 dominios, 45 servicios)
- **#SEEN_SERVICES**: Servicios vistos durante entrenamiento
- **#UNSEEN_SERVICES**: Servicios no vistos (zero-shot learning)

**Ejemplo - Servicio "Banks":**
```json
{
  "active_intent_accuracy": 0.9429,
  "average_cat_accuracy": 0.9818,
  "average_goal_accuracy": 0.9767,
  "joint_goal_accuracy": 0.6356,
  "requested_slots_f1": 0.9923,
  "requested_slots_precision": 0.9906,
  "requested_slots_recall": 0.9986
}
```

---

## üéØ Aplicaciones Pr√°cticas

### Caso de Uso: e-Contact Customer Service

Este modelo fue desarrollado para **e-Contact**, optimizando la experiencia del cliente en sistemas de di√°logo inteligentes:

- üè¶ **Banking**: Consultas de saldo, transferencias, historial
- üè® **Hotels**: Reservas, disponibilidad, amenidades
- ‚úàÔ∏è **Flights**: B√∫squeda de vuelos, reservas, cambios
- üçΩÔ∏è **Restaurants**: Reservas de mesas, b√∫squeda por ubicaci√≥n
- üè† **Real Estate**: B√∫squeda de propiedades, filtros

### Ventajas Clave

‚úÖ **Zero-Shot Learning**: Generaliza a nuevos dominios sin reentrenamiento
‚úÖ **Multi-Domain**: Maneja conversaciones multi-servicio
‚úÖ **Slot Carryover**: Mantiene contexto entre turnos
‚úÖ **Alta Precisi√≥n**: JGA 80.35% supera baselines anteriores
‚úÖ **Eficiencia**: Batch size 24 optimizado para GPUs T4

---

## üî¨ Optimizaci√≥n e Hiperpar√°metros

### Configuraci√≥n √ìptima (Iteraci√≥n 4)

```python
# En src/config.py
MAX_SEQ_LEN = 512
WORD_DROPOUT = 0.1
SCHEMA_AUGMENT_PROB = 0.1

BATCH_SIZE = 24                # √ìptimo para GPU T4
LEARNING_RATE = 2e-5           # AdamW optimizer
NUM_EPOCHS = 5                 # 4-5 epochs √≥ptimos
DROPOUT = 0.3                  # Para classification heads

# Dataset
MAX_INTENTS = 5
MAX_CAT_VALUES = 11
MAX_SLOTS = 17
MAX_SLOTS_OTHER_SERVICE = 40
MAX_VALUES_PER_SERVICE = 23
```

### Proceso de Optimizaci√≥n

1. **Iteraci√≥n 1**: Baseline (Batch 16, 3 epochs) ‚Üí JGA 65.88%
2. **Iteraci√≥n 2**: Aumentar batch (24) ‚Üí JGA 79.80% (+13.92%)
3. **Iteraci√≥n 3**: M√°s epochs (4) ‚Üí JGA 80.57% (+0.77%)
4. **Iteraci√≥n 4**: Fine-tuning (5 epochs) ‚Üí JGA 80.35% (estable)

> **Conclusi√≥n:** 5 epochs con batch size 24 ofrece el mejor balance precisi√≥n/tiempo.

---

## üìö Referencias Bibliogr√°ficas

### Paper Principal

```bibtex
@inproceedings{kapelonis2022multitask,
  title={A Multi-Task BERT Model for Schema-Guided Dialogue State Tracking},
  author={Kapelonis, Eleftherios and Georgiou, Efthymios and Potamianos, Alexandros},
  booktitle={Interspeech 2022},
  pages={1448--1452},
  year={2022},
  doi={10.21437/Interspeech.2022-10852}
}
```

### C√≥digo Base Original

- **GitHub**: [lefteris12/multitask-schema-guided-dst](https://github.com/lefteris12/multitask-schema-guided-dst)
- **Dataset**: [Google DSTC8 Schema-Guided Dialogue](https://github.com/google-research-datasets/dstc8-schema-guided-dialogue)

### Trabajos Relacionados

1. **BERT-DST**: Chao & Lane (2019) - Scalable End-to-End DST
2. **MA-DST**: Kumar et al. (2020) - Multi-Attention Based DST
3. **SGD Dataset**: Rastogi et al. (2020) - Schema-Guided Dialogue
4. **Zero-Shot DST**: Li et al. (2021) - Generative Question Answering

---

## üë§ Autor y Contacto

![Gift-Firma de Correo Electr√≥nico  (Alta Resoluci√≥n)](https://github.com/user-attachments/assets/57071453-6805-4c5f-97de-e158cdcc3910)


**Oscar David Hospinal**
_AI/ML Engineer & Researcher_

### üîó Redes Sociales

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Oscar%20David%20Hospinal-blue?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/oscardavidhospinal/)
[![YouTube](https://img.shields.io/badge/YouTube-Oscar%20David%20Hospinal-red?style=flat-square&logo=youtube)](https://www.youtube.com/@oscardavidhospinal)
[![TikTok](https://img.shields.io/badge/TikTok-@hospinalsystems-black?style=flat-square&logo=tiktok)](https://www.tiktok.com/@hospinalsystems)
[![GitLab](https://img.shields.io/badge/GitLab-david.hospinal-orange?style=flat-square&logo=gitlab)](https://gitlab.com/david.hospinal)

### üìß Contacto

- **Email**: [oscardavid.hospinal@uc.cl](mailto:oscardavid.hospinal@uc.cl)
- **Portfolio**: [hospinalsystems.carrd.co](https://hospinalsystems.carrd.co/)

---

## üìÑ Licencia

Este proyecto est√° licenciado bajo la **MIT License** - ver el archivo [LICENSE](LICENSE) para detalles.

Link: https://hspinal-systems.notion.site/Multi-Task-BERT-Model-for-Schema-Guided-Dialogue-State-Tracking-DST-2c3bb517bf8b80a697a2dd8a8069799e

---

## üôè Agradecimientos

- **e-Contact** por el apoyo y contexto del proyecto
- **Google Research** por el dataset Schema-Guided Dialogue
- **Lefteris Kapelonis et al.** por el paper y c√≥digo base original
- **Hugging Face** por la librer√≠a Transformers
- **PyTorch Team** por el framework de deep learning

---

## üìå Hashtags

`#DialogueStateTracking` `#NLP` `#BERT` `#MultiTaskLearning` `#ConversationalAI` `#DeepLearning` `#PyTorch` `#Transformers` `#MachineLearning` `#AI` `#SchemaGuidedDialogue` `#VirtualAssistant` `#Chatbot` `#CustomerService` `#eContact`

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, dale una estrella en GitHub!**

![Banner Hospinal Systems](https://github.com/user-attachments/assets/e2da3307-c083-483b-bdda-8fceb8b911d1)


**üîî Suscr√≠bete a mi canal de YouTube para m√°s tutoriales de IA/ML**

</div>
